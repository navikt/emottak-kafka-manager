apiVersion: "nais.io/v1"
kind: "Alert"
metadata:
  name: "emottak-kafka-manager"
  namespace: "team-emottak"
  labels:
    "team": "team-emottak"
spec:
  receivers:
    slack:
      channel: "team-emottak-alerts-dev"
      prependText: "<here> | "
  alerts:
  - alert: "emottak-kafka-manager er nede"
    description: "App {{ $labels.app }} er nede i namespace {{ $labels.kubernetes_namespace }}"
    expr: "kube_deployment_status_replicas_available{deployment=\"emottak-kafka-manager\"} == 0"
    for: "2m"
    action: "kubectl describe pod {{ $labels.kubernetes_pod_name }} -n {{ $labels.kubernetes_namespace }}` for events, og `kubectl logs {{ $labels.kubernetes_pod_name }} -n {{ $labels.kubernetes_namespace }}` for logger"
    documentation: "https://github.com/navikt/team-emottak/somedoc"
    sla: "Responder innen 1 time i kontortid"
    severity: "danger"
  - alert: "emottak-kafka-manager har mye feil i loggene"
    expr: "(100 * sum by (log_app, log_namespace) (rate(logd_messages_total{log_app=\"emottak-kafka-manager\",log_level=~\"Warning|Error\"}[3m])) / sum by (log_app, log_namespace) (rate(logd_messages_total{log_app=\"emottak-kafka-manager\"}[3m]))) > 10"
    for: "3m"
    action: "Sjekk loggene til app {{ $labels.log_app }} i namespace {{ $labels.log_namespace }} for å se hvorfor det er så mye feil"
    sla: "Responder innen 1 time i kontortid"
    severity: "warning"